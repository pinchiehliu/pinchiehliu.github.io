<!DOCTYPE html>
<html lang="en-us">
	<head>
		<title>Example 1-3</title>
		<meta charset="UTF-8">
	</head>
	<body>
		<nav>
			This is a menu<br/>
			Item1<br/>
			Item2<br/>
			...
		</nav>
		<article>
			<!-- From h1 to h6 -->
			<h1>This is an article.</h1>
			<section>
				<h2>This is a sub-heading.</h2>>
				In recent weeks, Facebook, Twitter and YouTube, as well as less politics-focused platforms like TikTok and Pinterest, have all released new policies on how to stem the spread of election and voting disinformation, such as removing or labeling false voting information or claims of election rigging. Now they are grappling with how to enforce those new measures if the results of the election are unclear for a prolonged period or contested.
			</section>
			<section>
				<h2>This is a second sub-heading.</h2>				
				<p>
					<h4>This is a heading for a paragraph.</h4>
					The range of platforms’ contingency plans includes what to do if a candidate prematurely declares victory before the results have been made official to how to stop videos calling into question the legitimacy of the election from going viral. In an indication of how starkly Twitter sees the potential impact, the company has said it will take action on tweets “inciting unlawful conduct to prevent a peaceful transfer of power or orderly succession” – a jarring line to read about an American election.
				</p>
				<p>
					“Within that context, whatever social media platforms do is null and void. The election results will be confused — that’s just a foregone conclusion,” says Graham Brookie, the director of the Atlantic Council’s Digital Forensic Research Lab, which tracks misinformation.
				</p>
			</section>
		</article>
	</body>
</html>